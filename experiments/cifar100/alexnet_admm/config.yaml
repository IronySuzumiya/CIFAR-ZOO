# net architecture
architecture: alexnet

# log and checkpoint
data_path: ./data
ckpt_path: ./
ckpt_name: alexnet

# datasets
num_classes: 100
dataset: cifar100 

# training parameters
use_gpu: True
input_size: 32
epochs: 120
batch_size: 128
test_batch: 200
eval_freq: 2
workers: 4

# optimizer
optimize:
  momentum: 0.9
  weight_decay: 0.0005
  nesterov: True

# regularization
mixup: False
mixup_alpha: 0.4

augmentation:
  normalize: True
  random_crop: True
  random_horizontal_filp: True
  cutout: False
  holes: 1
  length: 8

# learning rate scheduler
lr_scheduler:
  # type: STEP or COSINE or HTD
  type: STEP    
  base_lr: 0.1
  # only for STEP
  lr_epochs: [30, 50, 70, 95, 105, 115] 
  lr_mults: 0.1
  # for HTD and COSINE
  min_lr: 0.0
  # only for HTD
  lower_bound: -6.0
  upper_bound: 3.0

pruning:
  method: ADMM
  pre_epochs: 10
  epochs: 70
  re_epochs: 40
  rho: 0.01
  percent: [0.8, 0.92, 0.93, 0.94, 0.95, 0.99]
  ou_height: 4
  ou_width: 4